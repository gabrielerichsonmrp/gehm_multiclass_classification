---
title: "multiclass_classification"
author: "by Gabriel Erichson"
output: 
  html_document:
    df_print: paged
    code_folding: hide
    toc: true
    toc_depth: 2
    toc_float: 
      collapsed: true
    number_sections: true
    theme: sandstone
    highlight: haddock
    css: style.css
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	fig.align = "center",
	message = FALSE,
	warning = FALSE,
	comment = "#>",
	result = "hide"
)

options(scipen = 9999999)
#rm(list=ls())

library(tidyverse)
library(data.table)
library(paletti)
library(GGally)
library(ggplot2)
library(plotly)
library(rsample) # Initial Split
library(partykit) 
library(rpart) #Decision Tree
library(rpart.plot) #Decision Tree
library(caret) #Confussion Matrix
library(randomForest) #random forest
library(e1071) # naive bayes
library(nnet) #multinomial logistic regression
library(gridExtra)
library(grid)

```


```{r, include=FALSE}
#COLORS
library(ggthemes)
library(paletti)
# WARNA
mycolorfill = c(
  
  light_blue="#2f4b7c", 
  smooth_blue ="#4B87CB",
  light_purple ="#665191",
  dark_pink="#a05195", 
  light_pink="#d45087", 
  light_red="#f95d6a", 
  dark_orange="#ff6347",
  semi_orange="#e79658",
  orange="#dda15a",
  cream="#b59378",
  dark_cream="#A57F5F",
  choc="#85664B",
  dark_choc="#6b5340",
  light_orange="#ff7c43"
)


viz_palette(mycolorfill)
mycolor_fill  <- get_scale_fill(get_pal(mycolorfill))
mycolor_color <- get_scale_color(get_pal(mycolorfill))
mycolor_hex <- get_hex(mycolorfill)

```


# Intro
Bob telah memulai perusahaan selulernya sendiri. Dia ingin berjuang keras supaya bisa menjadi perusahaan besar seperti Apple, Samsung dll. Kendalanya, dia tidak tahu bagaimana memperkirakan kelas harga ponsel yang diciptakan perusahaannya? Di pasar telepon seluler yang kompetitif ini Bob tidak ingin berasumsi begitu saja, sehingga ia mengumpulkan data penjualan ponsel dari berbagai perusahaan. Bob ingin mengetahui hubungan antara fitur-fitur ponsel (misalnya: - RAM, Memori Internal, dll) untuk menentukan kelas harga jualnya, sehingga ia dapat melakukan pemasaran ke masing-masing segmen customer dengan lebih efektif. Dalam hal ini, Bob sudah mengumpulkan data penjualan ponsel dengan dengan kelas harga *low cost*, *medium cost*, *high cost* dan *very high cost*. Dalam hal ini, Bob membutuhkan bantuan untuk merprediksi setiap ponsel yang sudah diciptakan perusahaannya masuk ke kelas harga mana.


# Data Preparation {.tabset .tabset-fade .tabset-pills}
## Read Data
**Dataset terdiri dari 2000 data dengan 21 variabel**
```{r}
phone <- read.csv("data_input/phone.csv")
data.frame("total.data" = dim(phone)[1],
           "total.variabel" = dim(phone)[2])
```

<br>

**10 Data teratas**
```{r}
head(phone,10)
```

<br>

**10 Data terbawah**

```{r}
tail(phone, 10)
```


## Variable Description

Berikut ini deskripsi dari masing-masing variabel dari dataset ini:

Variable        |    Description                      |  Nilai
----------------|-------------------------------------|-------------------------------------------------------------
battery_power   | Kapasitas baterai (mAh)             | mAH
blue            | Support Bluetooth                   | Ya: 1, Tidak: 0
clock_speed     | Kecepatan microprocessor            | GHz
dual_sim        | Support Dual Sim                    | Ya: 1, Tidak: 0
fc              | Resolusi Kamera Depan               | Megapixel
four_g          | Support 4G                          | Ya: 1, Tidak: 0
int_memory      | Kapasitas Memori internal           | Gigabyte
m_dep           | Ketebelan device                    | Centimeter
mobile_wt       | Berat Device                        | Gram
n_cores         | Jumlah Core dari processor          | Satuan Angka
pc              | Resolusi Kamera Utama               | Megapixel
px_height       | Resolusi Tinggi Layar               | Pixel
px_width        | Resolusi Lebar Layar                | Pixel
ram             | Kapasitas RAM                       | Megabyte
sc_h            | Tinggi Layar                        | Centimeter
sc_w            | Lebar Layar                         | Centimeter
talk_time       | Total waktu pemakaian normal        | Jam
three_g         | Support 3G                          | Ya: 1, Tidak: 0
touch_screen    | Support layar sentuh                | Ya: 1, Tidak: 0
wifi            | Support Wifi                        | Ya: 1, Tidak: 0
price_range     | Kelas harga *Target Variabel*       | low cost:0, medium cost:1, high cost:2 dan very high cost:3




# Data Pre-processing {.tabset .tabset-fade .tabset-pills}
## Data Structure
Berikut ini struktur dataset yang ada:
```{r}
glimpse(phone)
```
<br>

Berdasarkan struktur data diatas, terdapat variabel-variabel yang tipe datanya perlu disesuaikan lagi berdasar sifat datanya sesuai dengan deskripsi variabel yang sudah dijelaskan pada poin 2.2. Adapun variabel yang perlu disesuaikan yaitu:
  1. *blue* :  di-konversi dari integer menjadi factor/kategorik <br>
  2. *dual_sim* : di-konversi dari integer menjadi factor/kategorik <br>
  3. *four_g* : di-konversi dari integer menjadi factor/kategorik <br>
  4. *three_g* : di-konversi dari integer menjadi factor/kategorik <br>
  5. *touch_screen* : di-konversi dari integer menjadi factor/kategorik <br>
  6. *wifi* : di-konversi dari integer menjadi factor/kategorik <br>
  7. *price_range* : di-konversi dari integer menjadi factor/kategorik dengan level **low cost**, **medium cost**, **high cost**, **very high cost**

```{r}
phone <- phone %>%
  mutate(
    blue = as.factor(blue),
    dual_sim  = as.factor(dual_sim),
    four_g = as.factor(four_g),
    three_g = as.factor(three_g),
    touch_screen = as.factor(touch_screen),
    wifi = as.factor(wifi),
    price_range = as.factor(price_range),
    price_range = sapply(price_range, switch,"low cost","medium cost", "high cost","very high cost"),
    price_range = ordered(price_range, levels=c("low cost","medium cost", "high cost","very high cost"))
  )
```
<br>

Berikut ini struktur dataset setelah dilakukan penyesuaian struktur data:

```{r}
glimpse(phone)
```
<br>

Berikut ini sampel dari 10 data teratas setelah dilakukan penyesuaian struktur data:
```{r}
head(phone,10)
```

<br>

***


## Missing Value

Tidak terdapat missing value pada dataset ini.
```{r}
colSums(is.na(phone))
```

<br>

***

## Duplicate Value

Tidak terdapat duplikat value pada dataset ini.
```{r}
data.frame("jumlah.seluruh.data"=nrow(phone),
           "jumlah.data.unik" = nrow(distinct(phone))
           )
```

<br>

***

## Data Summary
```{r}
summary(phone)
```

<br>

***

# EDA

```{r}
phone %>% group_by(price_range) %>% summarise(freq=n()) %>% 
ggplot( aes(x="", y=freq, fill=price_range)) + 
  geom_bar(stat="identity", width=1)+
  coord_polar("y", start=0) + 
  geom_text(aes(label = paste0(round((freq/sum(freq))*100), "%")),
            position = position_stack(vjust = 0.5),color="white")+
  scale_fill_manual(values=c(mycolor_hex("cream"),
                             mycolor_hex("dark_cream"),
                             mycolor_hex("choc"),
                             mycolor_hex("dark_choc"))) +
  labs(x = NULL, y = NULL, fill = "Price Range", title = "Data Proportion by Price Range")+
  theme_classic() + 
  theme(axis.line = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        plot.title = element_text(hjust = 0.5),
        axis.title=element_text(size=9,face="bold"), 
        legend.position = "right"
        )

```

Berdasarkan chart diatas, dataset yang dikumpulkan oleh Bob memiliki porsi kelas target yang **balance**, dimana masing-masing Price Range memiliki proporsi 25%. Proporsi kelas target yang seimbang sangat membantu proses pemodelan. Kemudian, bagaimana korelasi setiap variabel nya? 

```{r, warning=FALSE}
# corelation between predictors
ggcorr(phone,label = T, size=3, label_size = 3, hjust=0.95, 
       layout.exp = 3,low = mycolor_hex("semi_orange"), high = mycolor_hex("dark_choc"))+
  labs(
    title="Correlation Matrix for each Variables"
  )+
  theme_minimal()+
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.title=element_text(size=8,face="bold"), 
    axis.text.y=element_blank()
  )

```

Matriks korelasi diatas menunjukan sebagaian besar variabel bersifat independen atau tidak saling berkorelasi, kecuali:
  * **sc_w** dan **sc_h** memiliki korelasi positif sebesar 0.5 <br>
  * **px_width** dan **px_height** memiliki korelasi positif sebesar 0.5 <br>
  * **fc** dan **pc**memiliki korelasi positif sebesar 0.6 <br>


<br>

***

# Cross Validation

Dari 2000 data observasi, saya membagi **80% sebagai data train** dan **20% sebagai data test**. Data train digunakan untuk melakukan pemodelan dan data test dianggap sebagai unseen data yang digunakan untuk menguji seberapa baik model yang dibuat. Dapat dilihat pada chart dibawah, setiap target variable memiliki proporsi data train dan data test yang seimbang. Setiap target variable memiliki data train sebanyak 401 observasi dan memiliki data test sebanyak 99 observasi. Karena proporsi kelas target sudah sesuai maka dapat langsung dilanjutkan ke tahap pemodelan.

```{r}
set.seed(123)
split <- initial_split(phone, prop = 0.8, strata = "price_range")
phone_train <- training(split)
phone_test <- testing(split)

df_split <- rbind(
data.frame(table(phone_train$price_range),"type"="train"),
data.frame(table(phone_test$price_range),"type"="test")) %>% 
  mutate(
    Var1 = as.factor(Var1),
    type = as.factor(type)
  ) 

ggplot(df_split, aes(x=Var1,y=Freq, fill=type))+
  geom_col(position = "dodge")+
  geom_text(aes(label=Freq, y=Freq+20), size=3, position = position_dodge(width = 1))+
  labs(x = "Price Class", 
       y = "Frequency", 
       fill = "Data", 
       title = "Price Range: Proportion Train vs Test")+
  theme_minimal()+
  theme(
      axis.title=element_text(size=9,face="bold"),
      axis.text.x=element_text(size=10),
      axis.text.y=element_text(size=10)
      )+
  mycolor_fill()

```



<br>

***


# Modelling {.tabset .tabset-fade .tabset-pills}

Seperti yang dijelaskan pada intro diawal, Bob ingin memprediksi sebuah ponsel masuk ke kelas harga **low cost**, **medium cost**, **high cost** atau **very high cost**. Berdasarkan dataset yang dimiliki, maka yang menjadi target variabel untuk diprediksi adalah *price_range*. Proses pemodelan kali ini mengunakan beberapa metode klasifikasi yaitu Naive Bayes, Decision Tree, Random Forest dan Multinomial Logistic Regression. 


```{r}
ggplotConfusionMatrix <- function(my_title,dat_type,cfm,low_color,high_color){
  my_subtitle <- paste("Data:",dat_type,"    ",
                       "Accuracy:", paste(round((cfm$overall[1])*100,2),"%"),
                       "   ",
                       "Kappa:", paste(round((cfm$overall[2])*100,2),"%"))
  plot <-
    ggplot(data = as.data.frame(cfm$table),aes(x = Reference, y = Prediction)) +
    geom_tile(aes(fill = log(Freq)), colour = "white") +
    geom_text(aes(x = Reference, y = Prediction, label = Freq),color="white") +
    labs(
      title = my_title,
      subtitle = my_subtitle,
      x = "Actual",
      y = "Prediction"
    )+
    theme_minimal()+
    theme(
          title = element_text(size=14),
          
          axis.title=element_text(size=12, face="bold"),
          axis.text.x=element_text(size=12),
          legend.position = "none"
          ) +
    scale_fill_gradient(low=low_color,na.value = "#C0C0C0", high=high_color)
  
  
  return(plot)
}
```


## Naive Bayes

Metode Naive Bayes memiliki asumsi awal yaitu semua variabel bersifat independen atau tidak saling berkorelasi. Pada matriks korelasi diatas menunjukan beberapa variabel memiliki korelasi, sehingga dapat disimpulkan bahwa metode Naive Bayes akan kurang maksimal untuk case kalsifikasi ini. Namun, mari kita tetap kita coba. Berikut hasilnya:

```{r}
# Model Fitting
nvb_model <- naiveBayes(price_range ~ ., phone_train, laplace = 1)

# Predict
nvb_probability <- predict(nvb_model, phone_test, type = "raw")
nvb_prediction <- predict(nvb_model, phone_test, type = "class")

# Data Predict
nvb_result <- cbind(phone_test, price_range_prediction=nvb_prediction,
                    round(nvb_probability,3))

nvb_result <- nvb_result[,c(21,22,23,24,25,26)] %>% 
  setnames("price_range", "price_range_actual") %>%
  arrange(price_range_actual) %>% 
  mutate(
    no=seq(1:nrow(phone_test))
  ) %>% 
  select(7,1,2,3,4,5,6)

nvb_result

```

Data diatas merupakan hasil prediksi metode Naive Bayes terhadap data tes. **price_range_actual** merupakan data sebenarnya dan **price_range_prediction** merupakan data hasil prediksi, kemudian Data **low cost, medium cost, high cost dan very high cost** merupakan nilai probability terhadap setiap kelas dari target variabel. Sehingga, hasil prediksi pada **price_range_prediction** diambil berdasarkan nilai probability yang paling tinggi. Dapat dilihat pada data diatas, hasil prediksi masih banyak tidak sesuai dengan nilai aktualnya. Selain itu, terdapat data yang nilai probability kelas target nya cenderung tidak jauh berbeda antara satu dan lainnya, misalkan data nomor 2,20 dan 28. Hal ini menunjukan tingkat akurasi hasil prediksi yang kurang maksimal. Mari kita cek hasil evaluasinya menggunakan Confussion Matrix: 


```{r}
# Evaluation
cm_bayes <- confusionMatrix(
  data =nvb_result$price_range_prediction, 
  reference =nvb_result$price_range_actual
)

ggplotConfusionMatrix(my_title = "Confussion Matrix: Naive Bayes",
                      dat_type="Test",
                      cfm=cm_bayes,
                      low_color=mycolor_hex("smooth_blue"),
                      high_color =mycolor_hex("light_blue"))

```

Hasil evaluasi pada Confussion Matrix diatas menunjukan model Naive Bayes yang sudah dibuat memiliki tingkat akurasi **83.84%** dalam memprediksi kelas harga. Jika dilihat, hasil prediksi dan aktual yang ditebak benar memang menunjukan selisih yang cukup besar. Hasil Prediksi pada harga kelas Low Cost meleset sebanyak 15 ponsel, hasil prediksi harga kelas Medium Cost meleset sebanyak 15 ponsel, hasil prediksi harga kelas High Cost meleset 22 ponsel dan hasil prediksi Harga kelas Very Hight Cost meleset 12 ponsel. Mari kita coba metode Decision Tree. 

***

<br>


## Decision Tree

Decision tree merupakan suatu metode klasifikasi yang menggunakan struktur pohon, dimana setiap node merepresentasikan atribut dan cabangnya merepresentasikan nilai dari atribut, sedangkan daunnya digunakan untuk merepresentasikan kelas. Decision tree merupakan metode klasifikasi yang cukup **powerfull** karena *memperbolehkan antar prediktornya saling berkorelasi*, *prediktor* juga dapat berupa *data numerik ataupun kategorik* dan cukup *interpretabale*  

```{r}
# Model Fitting
dtree_model <- ctree(formula = price_range ~ ., 
                     data = phone_train,
                     control = ctree_control(mincriterion = 0.90))
# plot(dtree_model, type = "simple")
# levels(phone$price_range)


# Predict data train
dtree_prediction_train <- predict(dtree_model,phone_train)
dtree_probability_train <- predict(dtree_model,phone_train, type="prob")
dtree_probability_train <- data.frame(matrix(unlist(dtree_probability_train), 
                                             nrow=nrow(phone_train), byrow=T),stringsAsFactors=FALSE)
colnames(dtree_probability_train) <- c("low_price","medium_price","high_price","very_high_price")

# Train Data Predict
dtree_result_train <- cbind(phone_train, price_range_prediction=dtree_prediction_train,
                    round(dtree_probability_train,3))

dtree_result_train <- dtree_result_train[,c(21,22,23,24,25,26)] %>% 
  setnames("price_range", "price_range_actual") %>%
  arrange(price_range_actual) %>% 
  mutate(
    no=seq(1:nrow(phone_train))
  ) %>% 
  select(7,1,2,3,4,5,6)



# Predict data test
dtree_prediction <- predict(dtree_model,phone_test)
dtree_probability <- predict(dtree_model,phone_test, type="prob")
dtree_probability <- data.frame(matrix(unlist(dtree_probability), 
                                       nrow=nrow(phone_test), byrow=T),stringsAsFactors=FALSE)
colnames(dtree_probability) <- c("low_price","medium_price","high_price","very_high_price")

# Test Data Predict
dtree_result <- cbind(phone_test, price_range_prediction=dtree_prediction,
                    round(dtree_probability,3))

dtree_result <- dtree_result[,c(21,22,23,24,25,26)] %>% 
  setnames("price_range", "price_range_actual") %>%
  arrange(price_range_actual) %>% 
  mutate(
    no=seq(1:nrow(phone_test))
  ) %>% 
  select(7,1,2,3,4,5,6)

dtree_result

```


Data diatas merupakan hasil prediksi metode Decision Tree terhadap data tes. **price_range_actual** merupakan data sebenarnya dan **price_range_prediction** merupakan data hasil prediksi, kemudian Data **low cost, medium cost, high cost dan very high cost** merupakan nilai probability terhadap setiap kelas dari target variabel. Sehingga, hasil prediksi pada **price_range_prediction** diambil berdasarkan nilai probability yang paling tinggi. Dapat dilihat bahwa hasil prediksi memang masih banyak yang belum sesuai, namun jika dilihat dari pola nilai probability kelas target nya cenderung jauh berbeda antara satu dan lainnya jika dibandingkan dengan metode Naive Bayes. Mari kita cek hasil evaluasinya menggunakan Confussion Matrix: 


```{r, fig.asp=0.5, fig.width = 12}
# Evaluation
cfm_dtree_train <- confusionMatrix(
  data =dtree_result_train$price_range_prediction, 
  reference =dtree_result_train$price_range_actual
)

ggplotConfusionMatrix(my_title = "Decision Tree: Model Evaluation on Data Train vs Data Test using Confussion Matrix",
                      dat_type="Train",
                      cfm=cfm_dtree_train,
                      low_color=mycolor_hex("smooth_blue"),
                      high_color =mycolor_hex("light_blue")) -> dtree_p1


cfm_dtree <- confusionMatrix(
  data =dtree_result$price_range_prediction, 
  reference =dtree_result$price_range_actual
)


ggplotConfusionMatrix(my_title = "",
                      dat_type="Test",
                      cfm=cfm_dtree,
                      low_color=mycolor_hex("cream"),
                      high_color =mycolor_hex("dark_choc")) -> dtree_p2


grid.arrange(dtree_p1, dtree_p2, ncol = 2)

```

Hasil evaluasi menggunakan Confussion Matrix diatas menunjukan model Decision Tree yang sudah dibuat lumayan fit, selisih tingkat akurasi antara hasil prediksi data train dan data test hanya sebesar **3.85%**. Tingkat akurasi hasil klasifikasi juga lumayan bagus, dimana pada data train sebesar **90.21%** dan tingkat akurasi pada data test sebesar **86.36%**. Meskipun begitu, hasil prediksi dan aktual yang ditebak benar memang masih menunjukan selisih yang cukup besar. Hasil Prediksi data test pada harga kelas Low Cost meleset sebanyak 10 ponsel, hasil prediksi harga kelas Medium Cost meleset sebanyak 15 ponsel, hasil prediksi harga kelas High Cost meleset 17 ponsel dan hasil prediksi Harga kelas Very Hight Cost meleset 13 ponsel. Namun, dapat kita simpulkan bahwa metode Decision Tree lebih baik daripada metode Naive Bayes untuk case ini. Mari kita coba metode Random Forest. 


***

<br>

## Random Forest

## Random Forest

```{r}
rf_model_origin <- randomForest(price_range ~ ., 
                                data = phone_train, 
                                importance=TRUE, ntree = 500)
plot(rf_model_origin, main="Random Forest")


rf_prediction_original <- predict(rf_model_origin, phone_test)
confusionMatrix(
  rf_prediction_original,
   phone_test$price_range
)

```


***

<br>


## Random Forest with K-Fold

```{r}
# I decide to use nearZeroVar to identify low variance of each observation variable
# each factor has been converted before 
#nzero_var <- nearZeroVar(phone) 

# exclude each variable that has low variance
#phone_rf <- phone[,-nzero_var]
#ncol(phone_rf)

# Random Forest method with K-Fold Cross Validation
# set.seed(123)
# rf_model <- train(price_range ~., 
#                   data = phone_train, 
#                   method = "rf", 
#                   trControl= trainControl(method = 'repeatedcv', number = 20, repeats = 20))
# 
# wd <-  as.character(getwd())
# saveRDS(object=rf_model, file=paste(paste(wd,"/model/",sep = ""),"phone_random_forest.rds",sep=""))

rf_model <- readRDS("model/phone_random_forest.rds")


rf_model$finalModel
#summary(rf_model$finalModel)
#rf_model$finalModel[c("call", "confusion","oob.times")]

plot(rf_model)
varImp(rf_model)


plot(rf_model$finalModel)
legend("topright", colnames(rf_model$finalModel$err.rate),
       col=1:6,cex=0.8,fill=1:6)


rf_prediction <- predict(rf_model, phone_test)
confusionMatrix(
  rf_prediction,
   phone_test$price_range
)





```


***

<br>



## Multinomial Logistic Regression
```{r}
multinom_model <- multinom(price_range~.,data=phone_train)
summary(multinom_model)
#head(round(fitted(multinom_model),9),1)
#head(fitted(multinom_model),1)
multinom_predict <- predict(multinom_model,phone_test, type="probs")

phone_multinome_predict <- phone_test %>% 
  mutate(
    predict_price_range= predict(multinom_model, phone_test)
  )

phone_multinome_predict <- cbind(phone_multinome_predict,
                                 round(predict(multinom_model, phone_test, type = "probs"),9))


confusionMatrix(
  phone_multinome_predict$predict_price_range,
   phone_test$price_range
)

```



# Pertanyaan
1. Apa bedanya Random Forest dan Random Forest using K-Fold?
2. Bagaimana cara menentukan K-Fold?
3. Bagaimana cara tunning model Decission Tree, Naive Bayes dan Random Forest?
