---
title: "Mobile Price Classification"
author: "by Gabriel Erichson"
output:
  html_document:
    df_print: paged
    code_folding: hide
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: true
    number_sections: true
    theme: sandstone
    highlight: haddock
    css:  style.css
  pdf_document: default
---

<head>
		<title>Mobile Price Classification</title>
		<link rel="icon" href="assets/logo.png" type="image/png">
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
</head>

Github: https://github.com/gabrielerichsonmrp/gehm_multiclass_classification <br>

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	fig.align = "center",
	message = FALSE,
	warning = FALSE,
	comment = "#>",
	result = "hide"
)

options(scipen = 9999999)
#rm(list=ls())

library(tidyverse)
library(yardstick)
library(data.table)
library(paletti)
library(GGally)
library(ggplot2)
library(plotly)
library(rsample) # Initial Split
library(partykit) 
library(rpart) #Decision Tree
library(rpart.plot) #Decision Tree
library(caret) #Confussion Matrix
library(randomForest) #random forest
library(reprtree)
library(e1071) # naive bayes
library(nnet) #multinomial logistic regression
library(gridExtra)
library(grid)
library(knitr)
library(kableExtra)
library(cowplot)
library(formattable)

```


```{r, include=FALSE}
#COLORS
library(ggthemes)
library(paletti)
# WARNA
mycolorfill = c(
  
  light_blue="#2f4b7c", 
  smooth_blue ="#4B87CB",
  light_purple ="#665191",
  dark_pink="#a05195", 
  light_pink="#d45087", 
  light_red="#f95d6a", 
  dark_orange="#ff6347",
  semi_orange="#e79658",
  orange="#dda15a",
  cream="#b59378",
  dark_cream="#A57F5F",
  choc="#85664B",
  dark_choc="#6b5340",
  light_orange="#ff7c43"
)


viz_palette(mycolorfill)
mycolor_fill  <- get_scale_fill(get_pal(mycolorfill))
mycolor_color <- get_scale_color(get_pal(mycolorfill))
mycolor_hex <- get_hex(mycolorfill)

```



# Intro
Bob telah memulai perusahaan selulernya sendiri. Dia ingin berjuang keras supaya bisa menjadi perusahaan besar seperti Apple, Samsung dll. Kendalanya, dia tidak tahu bagaimana memperkirakan kelas harga ponsel yang diciptakan perusahaannya? Di pasar telepon seluler yang kompetitif ini Bob tidak ingin berasumsi begitu saja, sehingga ia mengumpulkan data penjualan ponsel dari berbagai perusahaan. Bob ingin mengetahui hubungan antara fitur-fitur ponsel (misalnya: - RAM, Memori Internal, dll) untuk menentukan kelas harga jualnya, sehingga ia dapat melakukan pemasaran ke masing-masing segmen customer dengan lebih efektif. Bob sudah mengumpulkan data penjualan ponsel dengan dengan kelas harga *low cost*, *medium cost*, *high cost* dan *very high cost*. Dalam hal ini, Bob membutuhkan bantuan untuk merprediksi setiap ponsel yang sudah diciptakan perusahaannya masuk ke kelas harga mana.

<br>

# Data Preparation {.tabset .tabset-fade .tabset-pills}
Dataset ini didownload dari [Mobile Price Classification](https://www.kaggle.com/iabhishekofficial/mobile-price-classification) 

## Read Data
**Dataset terdiri dari 2000 data dengan 21 variabel**
```{r}
phone <- read.csv("data_input/phone.csv")
data.frame("total.data" = dim(phone)[1],
           "total.variabel" = dim(phone)[2])
```

<br>

**10 Data teratas**
```{r}
head(phone,10)
```

<br>

**10 Data terbawah**

```{r}
tail(phone, 10)
```


<br>


## Variable Description

Berikut ini deskripsi dari masing-masing variabel dari dataset ini:

Variable        |    Description                      |  Nilai
----------------|-------------------------------------|-------------------------------------------------------------
battery_power   | Kapasitas baterai (mAh)             | mAH
blue            | Support Bluetooth                   | Ya: 1, Tidak: 0
clock_speed     | Kecepatan microprocessor            | GHz
dual_sim        | Support Dual Sim                    | Ya: 1, Tidak: 0
fc              | Resolusi Kamera Depan               | Megapixel
four_g          | Support 4G                          | Ya: 1, Tidak: 0
int_memory      | Kapasitas Memori internal           | Gigabyte
m_dep           | Ketebelan device                    | Centimeter
mobile_wt       | Berat Device                        | Gram
n_cores         | Jumlah Core dari processor          | Satuan Angka
pc              | Resolusi Kamera Utama               | Megapixel
px_height       | Resolusi Tinggi Layar               | Pixel
px_width        | Resolusi Lebar Layar                | Pixel
ram             | Kapasitas RAM                       | Megabyte
sc_h            | Tinggi Layar                        | Centimeter
sc_w            | Lebar Layar                         | Centimeter
talk_time       | Total waktu pemakaian normal        | Jam
three_g         | Support 3G                          | Ya: 1, Tidak: 0
touch_screen    | Support layar sentuh                | Ya: 1, Tidak: 0
wifi            | Support Wifi                        | Ya: 1, Tidak: 0
price_range     | Kelas harga *Target Variabel*       | low cost:0, medium cost:1, high cost:2 dan very high cost:3


<br>


# Data Pre-processing {.tabset .tabset-fade .tabset-pills}
## Data Structure
Berikut ini struktur dataset yang ada:
```{r}
glimpse(phone)
```
<br>

Berdasarkan struktur data diatas, terdapat variabel-variabel yang tipe datanya perlu disesuaikan lagi berdasar sifat datanya sesuai dengan deskripsi variabel yang sudah dijelaskan pada poin 2.2. Adapun variabel yang perlu disesuaikan yaitu:
  1. *blue* :  di-konversi dari integer menjadi factor/kategorik <br>
  2. *dual_sim* : di-konversi dari integer menjadi factor/kategorik <br>
  3. *four_g* : di-konversi dari integer menjadi factor/kategorik <br>
  4. *three_g* : di-konversi dari integer menjadi factor/kategorik <br>
  5. *touch_screen* : di-konversi dari integer menjadi factor/kategorik <br>
  6. *wifi* : di-konversi dari integer menjadi factor/kategorik <br>
  7. *price_range* : di-konversi dari integer menjadi factor/kategorik dengan level **low cost**, **medium cost**, **high cost**, **very high cost**

```{r}
phone <- phone %>%
  mutate(
    blue = as.factor(blue),
    dual_sim  = as.factor(dual_sim),
    four_g = as.factor(four_g),
    three_g = as.factor(three_g),
    touch_screen = as.factor(touch_screen),
    wifi = as.factor(wifi),
    price_range = as.factor(price_range),
    price_range = sapply(price_range, switch,"low cost","medium cost", "high cost","very high cost"),
    price_range = ordered(price_range, levels=c("low cost","medium cost", "high cost","very high cost"))
  )
```
<br>

Berikut ini struktur dataset setelah dilakukan penyesuaian struktur data:

```{r}
glimpse(phone)
```
<br>

Berikut ini sampel dari 10 data teratas setelah dilakukan penyesuaian struktur data:
```{r}
head(phone,10)
```

<br>

***


## Missing Value

Tidak terdapat missing value pada dataset ini.
```{r}
colSums(is.na(phone))
```

<br>

***

## Duplicate Value

Tidak terdapat duplikat value pada dataset ini.
```{r}
data.frame("jumlah.seluruh.data"=nrow(phone),
           "jumlah.data.unik" = nrow(distinct(phone))
           )
```

<br>

***


# EDA

```{r}
phone %>% group_by(price_range) %>% summarise(freq=n()) %>% 
ggplot( aes(x="", y=freq, fill=price_range)) + 
  geom_bar(stat="identity", width=1)+
  coord_polar("y", start=0) + 
  geom_text(aes(label = paste0(round((freq/sum(freq))*100), "%")),
            position = position_stack(vjust = 0.5),color="white")+
  scale_fill_manual(values=c(mycolor_hex("cream"),
                             mycolor_hex("dark_cream"),
                             mycolor_hex("choc"),
                             mycolor_hex("dark_choc"))) +
  labs(x = NULL, y = NULL, fill = "Price Range", title = "Data Proportion by Price Range")+
  theme_classic() + 
  theme(axis.line = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        plot.title = element_text(hjust = 0.5),
        axis.title=element_text(size=9,face="bold"), 
        legend.position = "right"
        )

```

Berdasarkan chart diatas, dataset yang dikumpulkan oleh Bob memiliki porsi kelas target yang **balance**, dimana masing-masing Price Range memiliki proporsi 25%. Proporsi kelas target yang seimbang sangat membantu proses pemodelan. Kemudian, bagaimana korelasi setiap variabel nya? 

```{r, warning=FALSE}
# corelation between predictors
ggcorr(phone,label = T, size=3, label_size = 3, hjust=0.95, 
       layout.exp = 3,low = mycolor_hex("semi_orange"), high = mycolor_hex("dark_choc"))+
  labs(
    title="Correlation Matrix for each Variables"
  )+
  theme_minimal()+
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.title=element_text(size=8,face="bold"), 
    axis.text.y=element_blank()
  )

```

Matriks korelasi diatas menunjukan sebagaian besar variabel bersifat independen atau tidak saling berkorelasi, kecuali:<br>
  * **sc_w** dan **sc_h** memiliki korelasi positif sebesar 0.5 <br>
  * **px_width** dan **px_height** memiliki korelasi positif sebesar 0.5 <br>
  * **fc** dan **pc**memiliki korelasi positif sebesar 0.6 <br>


<br>

***

# Cross Validation

Dari 2000 data observasi, saya membagi **80% sebagai data train** dan **20% sebagai data test**. Data train digunakan untuk melakukan pemodelan dan data test dianggap sebagai unseen data yang digunakan untuk menguji seberapa baik model yang dibuat. Dapat dilihat pada chart dibawah, setiap target variable memiliki proporsi data train dan data test yang seimbang. Setiap target variable memiliki data train sebanyak 401 observasi dan memiliki data test sebanyak 99 observasi. Karena proporsi kelas target sudah sesuai maka dapat langsung dilanjutkan ke tahap pemodelan.

```{r}
set.seed(123)
split <- initial_split(phone, prop = 0.8, strata = "price_range")
phone_train <- training(split)
phone_test <- testing(split)

df_split <- rbind(
data.frame(table(phone_train$price_range),"type"="train"),
data.frame(table(phone_test$price_range),"type"="test")) %>% 
  mutate(
    Var1 = as.factor(Var1),
    type = as.factor(type)
  ) 

ggplot(df_split, aes(x=Var1,y=Freq, fill=type))+
  geom_col(position = "dodge")+
  geom_text(aes(label=Freq, y=Freq+20), size=3, position = position_dodge(width = 1))+
  labs(x = "Price Class", 
       y = "Frequency", 
       fill = "Data", 
       title = "Price Range: Proportion Train vs Test")+
  theme_minimal()+
  theme(
      axis.title=element_text(size=9,face="bold"),
      axis.text.x=element_text(size=10),
      axis.text.y=element_text(size=10)
      )+
   scale_fill_manual(values=c(mycolor_hex("smooth_blue"),
                             mycolor_hex("light_blue"))) 

```



<br>

***


# Modelling {.tabset .tabset-fade .tabset-pills}

Seperti yang dijelaskan pada intro diawal, Bob ingin memprediksi sebuah ponsel masuk ke kelas harga **low cost**, **medium cost**, **high cost** atau **very high cost**. Berdasarkan dataset yang dimiliki, maka yang menjadi target variabel untuk diprediksi adalah *price_range*. Proses pemodelan kali ini mengunakan beberapa metode klasifikasi yaitu Naive Bayes, Decision Tree, Random Forest dan Multinomial Logistic Regression. 


```{r}
# Fungsi ini digunakan untuk menampilkan hasil confussion matrix
ggplotConfusionMatrix <- function(my_title,dat_type,cfm,low_color,high_color){
  my_subtitle <- paste("Data:",dat_type,"    ",
                       "Accuracy:", paste(round((cfm$overall[1])*100,2),"%"),
                       "   ",
                       "Kappa:", paste(round((cfm$overall[2])*100,2),"%"))
  
  
  plot <- ggplot(data = as.data.frame(cfm$table),aes(x = Reference, y = Prediction)) +
    geom_tile(aes(fill = log(Freq)), colour = "white") +
    geom_text(aes(x = Reference, y = Prediction, label = Freq),color="white") +
    labs(
      title = my_title,
      subtitle = my_subtitle,
      x = "Actual",
      y = "Prediction"
    )+
    theme_minimal()+
    theme(
          title = element_text(size=14),
          axis.title=element_text(size=12, face="bold"),
          axis.text.x=element_text(size=12),
           axis.text.y=element_text(size=12),
          legend.position = "none"
          ) +
    scale_fill_gradient(low=low_color,na.value = "#C0C0C0", high=high_color)
  
  
  return(plot)
}

# Fungsi ini digunakan untuk menampilkan metrics summary
summaryMatrix <- function(data_train, v_actual_train, v_prediction_train, header_color_train,
                          data_test, v_actual_test, v_prediction_test, header_color_test){
 sm_train <- data_train %>%
    summarise(
      accuracy = paste(round((accuracy_vec(v_actual_train, v_prediction_train))*100,2),"%"),
      sensitivity = paste(round((sens_vec(v_actual_train, v_prediction_train))*100,2),"%"),
      specificity = paste(round((spec_vec(v_actual_train, v_prediction_train))*100,2),"%"),
      precision = paste(round((precision_vec(v_actual_train, v_prediction_train))*100,2),"%")
    )
 
sm_test <- data_test %>%
    summarise(
      accuracy = paste(round((accuracy_vec(v_actual_test, v_prediction_test))*100,2),"%"),
      sensitivity = paste(round((sens_vec(v_actual_test, v_prediction_test))*100,2),"%"),
      specificity = paste(round((spec_vec(v_actual_test, v_prediction_test))*100,2),"%"),
      precision = paste(round((precision_vec(v_actual_test, v_prediction_test))*100,2),"%")
    )
 
sm <- rbind(sm_train,sm_test)
sm <- cbind(data.frame(data=c("data train","data test")),sm)
sm %>% 
   mutate(
    data = color_tile(mycolor_hex("dark_choc"),mycolor_hex("light_blue"))(data)
    
  ) %>%
  kable("html", escape = F, align = "c") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F) %>%
  column_spec(1, bold = T, color = "white") %>%
  column_spec(column = 1:5, width = "18em") %>% 
#    column_spec(column = 1:4, background = header_color_train) %>% 
#    column_spec(column = 5:8, background = header_color_test) %>% 
 add_header_above(c("Metrics Summary Data Train vs Test" = 5)) 
}


```


## Naive Bayes

<p style="font-size:140%;"><b>Naive Bayes</b></p>

Metode Naive Bayes memiliki asumsi awal yaitu semua variabel bersifat independen atau tidak saling berkorelasi. Pada matriks korelasi diatas menunjukan beberapa variabel memiliki korelasi, sehingga dapat disimpulkan bahwa metode Naive Bayes akan kurang maksimal untuk case kalsifikasi ini. Namun, mari kita tetap kita coba. Berikut hasilnya:

```{r}
# Model Fitting
nvb_model <- naiveBayes(price_range ~ ., phone_train, laplace = 1)


# Predict Data Train
nvb_probability_train <- predict(nvb_model, phone_train, type = "raw")
nvb_prediction_train <- predict(nvb_model, phone_train, type = "class")

# Data Predict
nvb_result_train <- cbind(phone_train, price_range_prediction=nvb_prediction_train,
                    round(nvb_probability_train,3))

nvb_result_train <- nvb_result_train[,c(21,22,23,24,25,26)] %>% 
  setnames("price_range", "price_range_actual") %>%
  arrange(price_range_actual) %>% 
  mutate(
    no=seq(1:nrow(phone_train))
  ) %>% 
  select(7,1,2,3,4,5,6)




# Predict Data Test
nvb_probability <- predict(nvb_model, phone_test, type = "raw")
nvb_prediction <- predict(nvb_model, phone_test, type = "class")

# Data Predict
nvb_result <- cbind(phone_test, price_range_prediction=nvb_prediction,
                    round(nvb_probability,3))

nvb_result <- nvb_result[,c(21,22,23,24,25,26)] %>% 
  setnames("price_range", "price_range_actual") %>%
  arrange(price_range_actual) %>% 
  mutate(
    no=seq(1:nrow(phone_test))
  ) %>% 
  select(7,1,2,3,4,5,6)

nvb_result

```

Data diatas merupakan hasil prediksi metode Naive Bayes terhadap data tes. **price_range_actual** merupakan data sebenarnya dan **price_range_prediction** merupakan data hasil prediksi, kemudian Data **low cost, medium cost, high cost dan very high cost** merupakan nilai probability terhadap setiap kelas dari target variabel. Sehingga, hasil prediksi pada **price_range_prediction** diambil berdasarkan nilai probability yang paling tinggi. Dapat dilihat pada data diatas, hasil prediksi masih banyak tidak sesuai dengan nilai aktualnya. Selain itu, terdapat data yang nilai probability kelas target nya cenderung tidak jauh berbeda antara satu dan lainnya, misalkan data nomor 2,20 dan 28. Hal ini menunjukan tingkat akurasi hasil prediksi yang kurang maksimal. Mari kita cek hasil evaluasinya menggunakan Confussion Matrix: 


```{r, fig.asp=0.5, fig.width=12}
# Evaluation
# TRAIN FITTED VALUE
# PREDICT TEST
cm_bayes_train <- confusionMatrix(
  data = nvb_result_train$price_range_prediction, 
  reference =nvb_result_train$price_range_actual
)

ggplotConfusionMatrix(my_title = "Naive Bayes: Model Evaluation on Data Train vs Data Test using Confussion Matrix",
                      dat_type="Train",
                      cfm=cm_bayes_train,
                      low_color=mycolor_hex("smooth_blue"),
                      high_color =mycolor_hex("light_blue")) -> nvb1


# PREDICT TEST
cm_bayes <- confusionMatrix(
  data = nvb_result$price_range_prediction, 
  reference =nvb_result$price_range_actual
)

ggplotConfusionMatrix(my_title = "",
                      dat_type="Test",
                      cfm=cm_bayes,
                      low_color=mycolor_hex("cream"),
                      high_color =mycolor_hex("dark_choc")) -> nvb2


grid.arrange(nvb1, nvb2, ncol = 2)
```

```{r}
summaryMatrix(data_train=nvb_result_train,
              v_actual_train = nvb_result_train$price_range_actual,
              v_prediction_train = nvb_result_train$price_range_prediction,
              header_color_train = mycolor_hex("light_blue"),
              
              data_test=nvb_result,
              v_actual_test = nvb_result$price_range_actual,
              v_prediction_test = nvb_result$price_range_prediction,
              header_color_test = mycolor_hex("dark_choc")
              )
```


Hasil evaluasi pada Confussion Matrix diatas menunjukan model Naive Bayes yang sudah dibuat memiliki tingkat akurasi **83.84%** dalam memprediksi kelas harga. Jika dilihat, hasil prediksi dan aktual yang ditebak benar memang menunjukan selisih yang cukup besar. Hasil Prediksi pada harga kelas Low Cost meleset sebanyak 15 ponsel, hasil prediksi harga kelas Medium Cost meleset sebanyak 15 ponsel, hasil prediksi harga kelas High Cost meleset 22 ponsel dan hasil prediksi Harga kelas Very Hight Cost meleset 12 ponsel. Mari kita coba metode Decision Tree. 

***

<br>


## Decision Tree
<p style="font-size:140%;"><b>Decision Tree</b></p>
Decision tree merupakan suatu metode klasifikasi yang menggunakan struktur pohon, dimana setiap node merepresentasikan atribut dan cabangnya merepresentasikan nilai dari atribut, sedangkan daunnya digunakan untuk merepresentasikan kelas. Decision tree merupakan metode klasifikasi yang cukup **powerfull** karena *memperbolehkan antar prediktornya saling berkorelasi*, *prediktor* juga dapat berupa *data numerik ataupun kategorik* dan cukup *interpretabale*  

```{r}
# Model Fitting
dtree_model <- ctree(formula = price_range ~ ., 
                     data = phone_train)

# Predict data train
dtree_prediction_train <- predict(dtree_model,phone_train)
dtree_probability_train <- predict(dtree_model,phone_train, type="prob")
dtree_probability_train <- data.frame(matrix(unlist(dtree_probability_train), 
                                             nrow=nrow(phone_train), byrow=T),stringsAsFactors=FALSE)
colnames(dtree_probability_train) <- c("low_price","medium_price","high_price","very_high_price")

# Train Data Predict
dtree_result_train <- cbind(phone_train, price_range_prediction=dtree_prediction_train,
                    round(dtree_probability_train,3))

dtree_result_train <- dtree_result_train[,c(21,22,23,24,25,26)] %>% 
  setnames("price_range", "price_range_actual") %>%
  arrange(price_range_actual) %>% 
  mutate(
    no=seq(1:nrow(phone_train))
  ) %>% 
  select(7,1,2,3,4,5,6)



# Predict data test
dtree_prediction <- predict(dtree_model,phone_test)
dtree_probability <- predict(dtree_model,phone_test, type="prob")
dtree_probability <- data.frame(matrix(unlist(dtree_probability), 
                                       nrow=nrow(phone_test), byrow=T),stringsAsFactors=FALSE)
colnames(dtree_probability) <- c("low_price","medium_price","high_price","very_high_price")

# Test Data Predict
dtree_result <- cbind(phone_test, price_range_prediction=dtree_prediction,
                    round(dtree_probability,3))

dtree_result <- dtree_result[,c(21,22,23,24,25,26)] %>% 
  setnames("price_range", "price_range_actual") %>%
  arrange(price_range_actual) %>% 
  mutate(
    no=seq(1:nrow(phone_test))
  ) %>% 
  select(7,1,2,3,4,5,6)

dtree_result

```


Data diatas merupakan hasil prediksi metode Decision Tree terhadap data tes. **price_range_actual** merupakan data sebenarnya dan **price_range_prediction** merupakan data hasil prediksi, kemudian Data **low cost, medium cost, high cost dan very high cost** merupakan nilai probability terhadap setiap kelas dari target variabel. Sehingga, hasil prediksi pada **price_range_prediction** diambil berdasarkan nilai probability yang paling tinggi. Dapat dilihat bahwa hasil prediksi memang masih banyak yang belum sesuai, namun jika dilihat dari pola nilai probability kelas target nya cenderung jauh berbeda antara satu dan lainnya jika dibandingkan dengan metode Naive Bayes. Mari kita cek hasil evaluasinya menggunakan Confussion Matrix: 


```{r, fig.asp=0.5, fig.width = 12}
# Evaluation
cfm_dtree_train <- confusionMatrix(
  data =dtree_result_train$price_range_prediction, 
  reference =dtree_result_train$price_range_actual
)

ggplotConfusionMatrix(my_title = "Decision Tree: Model Evaluation on Data Train vs Data Test using Confussion Matrix",
                      dat_type="Train",
                      cfm=cfm_dtree_train,
                      low_color=mycolor_hex("smooth_blue"),
                      high_color =mycolor_hex("light_blue")) -> dtree_p1


cfm_dtree <- confusionMatrix(
  data =dtree_result$price_range_prediction, 
  reference =dtree_result$price_range_actual
)


ggplotConfusionMatrix(my_title = "",
                      dat_type="Test",
                      cfm=cfm_dtree,
                      low_color=mycolor_hex("cream"),
                      high_color =mycolor_hex("dark_choc")) -> dtree_p2

grid.arrange(dtree_p1, dtree_p2, ncol = 2)

```

```{r, echo=FALSE}

summaryMatrix(data_train=dtree_result_train,
              v_actual_train = dtree_result_train$price_range_actual,
              v_prediction_train = dtree_result_train$price_range_prediction,
              header_color_train = mycolor_hex("light_blue"),
              
              data_test=dtree_result,
              v_actual_test = dtree_result$price_range_actual,
              v_prediction_test = dtree_result$price_range_prediction,
              header_color_test = mycolor_hex("dark_choc")
              )

```

Hasil evaluasi model Decision Tree menggunakan Confussion Matrix diatas menunjukan Tingkat akurasi hasil klasifikasi lumayan bagus, dimana tingkat akurasi pada data train sebesar **90.21%** dan tingkat akurasi pada data test sebesar **86.36%**. Namun, Hasil prediksi dan aktual yang ditebak benar memang masih menunjukan selisih yang cukup besar. Hasil Prediksi data test pada harga kelas Low Cost meleset sebanyak 10 ponsel, hasil prediksi harga kelas Medium Cost meleset sebanyak 15 ponsel, hasil prediksi harga kelas High Cost meleset 17 ponsel dan hasil prediksi Harga kelas Very Hight Cost meleset 13 ponsel. Namun, dapat kita simpulkan bahwa metode Decision Tree lebih baik daripada metode Naive Bayes untuk case ini. Mari kita coba tunning untuk mengurangi. Meskipun begitu dapat dikatakan model ini adalah *underfit model* dengan selisih tingkat akurasi sebesar **3.85%**. <br>

Menurut saya pribadi selisih ini masih cukup besar, sehingga dapat kita lakukan pruning pada model yang sudah dibuat. Pruning merupakan bagian dari proses pembentukan decision tree. Saat pembentukan decision tree, beberapa node merupakan outlier maupun hasil dari noise data. Penerapan pruning pada decision tree, dapat mengurangi outlier maupun noise data pada decision tree awal sehingga dapat meningkatkan akurasi pada klasifikasi data. Algoritma Pruning sendiri memiliki kriteria value yaitu:<br>
  
  1. **mincriterion**: Nilainya adalah 1 - Alpha. Bekerja sebagai “regulator” untuk kedalaman pohon. Semakin kecil nilainya maka semakin kompleks pohon yang dihasilkan. Misal mincriterion = 0.8, maka p-value < 0.2 yang digunakan untuk melakukan split/memecah node. <br>
  2. **minsplit**: Jumlah observasi minimal pada pada node sebelum melakukan split. Misal minsplit = 50, maka node tersebut tidak akan dipecah jika observasi yang terdapat di dalam node < 50.<br>
  3. **minbucket**: jumlah observasi minimal pada terminal node. Misal minbucket = 3, maka setiap terminal node yang terbentuk harus mempunyai minimal 3 observasi.<br>


Saya sudah mencoba beberapa nilai untuk masing-masing mincriterion, minsplit dan minbucket terhadap model tree yang sudah dibuat, namun tidak saya cantumkan semua disini. Dari hasil percobaan yang saya lakukan didapat pruning terbaik dengan kriteria **mincriterion = 0.92 minsplit = 16**. Mari kita lihat hasilnya:

```{r, fig.asp=0.5, fig.width = 12}
# Model Decision Tress & Pruning
dtree_model <- ctree(formula = price_range ~ ., 
                     data = phone_train,
                     control = ctree_control(mincriterion = 0.92, minsplit = 16))

# Predict data train
dtree_prediction_train <- predict(dtree_model,phone_train)
dtree_probability_train <- predict(dtree_model,phone_train, type="prob")
dtree_probability_train <- data.frame(matrix(unlist(dtree_probability_train), 
                                             nrow=nrow(phone_train), byrow=T),stringsAsFactors=FALSE)
colnames(dtree_probability_train) <- c("low_price","medium_price","high_price","very_high_price")

# Train Data Predict
dtree_result_train <- cbind(phone_train, price_range_prediction=dtree_prediction_train,
                    round(dtree_probability_train,3))

dtree_result_train <- dtree_result_train[,c(21,22,23,24,25,26)] %>% 
  setnames("price_range", "price_range_actual") %>%
  arrange(price_range_actual) %>% 
  mutate(
    no=seq(1:nrow(phone_train))
  ) %>% 
  select(7,1,2,3,4,5,6)



# Predict data test
dtree_prediction <- predict(dtree_model,phone_test)
dtree_probability <- predict(dtree_model,phone_test, type="prob")
dtree_probability <- data.frame(matrix(unlist(dtree_probability), 
                                       nrow=nrow(phone_test), byrow=T),stringsAsFactors=FALSE)
colnames(dtree_probability) <- c("low_price","medium_price","high_price","very_high_price")

# Test Data Predict
dtree_result <- cbind(phone_test, price_range_prediction=dtree_prediction,
                    round(dtree_probability,3))

dtree_result <- dtree_result[,c(21,22,23,24,25,26)] %>% 
  setnames("price_range", "price_range_actual") %>%
  arrange(price_range_actual) %>% 
  mutate(
    no=seq(1:nrow(phone_test))
  ) %>% 
  select(7,1,2,3,4,5,6)


# Evaluation (Pruning)
cfm_dtree_train <- confusionMatrix(
  data =dtree_result_train$price_range_prediction, 
  reference =dtree_result_train$price_range_actual
)

ggplotConfusionMatrix(my_title = "Pruning Decision Tree: Model Evaluation on Data Train vs Data Test using Confussion Matrix",
                      dat_type="Train",
                      cfm=cfm_dtree_train,
                      low_color=mycolor_hex("smooth_blue"),
                      high_color =mycolor_hex("light_blue")) -> dtree_p1


cfm_dtree <- confusionMatrix(
  data =dtree_result$price_range_prediction, 
  reference =dtree_result$price_range_actual
)


ggplotConfusionMatrix(my_title = "",
                      dat_type="Test",
                      cfm=cfm_dtree,
                      low_color=mycolor_hex("cream"),
                      high_color =mycolor_hex("dark_choc")) -> dtree_p2

grid.arrange(dtree_p1, dtree_p2, ncol = 2)


```

```{r, echo=FALSE}

summaryMatrix(data_train=dtree_result_train,
              v_actual_train = dtree_result_train$price_range_actual,
              v_prediction_train = dtree_result_train$price_range_prediction,
              header_color_train = mycolor_hex("light_blue"),
              
              data_test=dtree_result,
              v_actual_test = dtree_result$price_range_actual,
              v_prediction_test = dtree_result$price_range_prediction,
              header_color_test = mycolor_hex("dark_choc")
              )

```

Berdasar hasil evaluasi diatas, model decision tree dengan penerapan pruning yang dibuat mengalami peningkatan akurasi meskipun kurang signifikan. Tingkat akurasi pada data train sebesar **90.59%** atau meningkat **0.38%** dan tingkat akurasi pada data test sebesar **87.63%** atau meningkat **1.27%**. Model ini masih underfit, namun selisih tingkat akurasinya juga menurun menjadi **2.96%** atau menurun **0.89%**. Meskipun begitu perubahan tidak signifikan, dapat dikatan pruning yang dilakukan dapat meningkatan performa model Decision Tree sebelumnya. Hasil ini memang masih kurang baik, maka mari kita coba menggunakan metode Random Forest.


***

<br>

## Random Forest
<p style="font-size:140%;"><b>Random Forest</b></p>
Random forest merupakan metode klasifikasi berbasis ensamble method dan dibangun dari beberapa decision tree yang berbeda karakteristiknya. Ensamble method sendiri merupakan dimana terdapat beberapa model berbeda yang dilatih untuk memecahkan masalah yang sama dan digabungkan untuk mendapatkan hasil terbaik. Penerapannya pada random forest yaitu metode Random Forest akan membangun beberapa Decision Tree yang dimana setiap membangun 1 tree digunakan observasi dan prediktor yang berbeda dari hasil sampling untuk dilatih dan mencari hasil terbaik. Performa model Random Forest ini akan kurang baik apabila data prediktor memiliki variansi rendah atau variansinya mendekati 0(nol). Maka, sebelum melakukan pemodelan mari kita cek variansinya dahulu:

```{r}
# each factor has been converted before 
nzero_var <- nearZeroVar(phone)

# exclude each variable that has low variance
#phone_rf <- phone[,-nzero_var]
#ncol(phone_rf)
```
Hasil pengecekan menggunakan fungsi nearZeroVar diatas menunjukan tidak ada prediktor yang memiliki variansi rendah, sehingga dapat dilanjutkan ke proses pemodelan.



### Random Forest
Model random forest akan memulai dengan inisialisasi random, maka perlu dilakukan set.seed supaya nilai yang dihasilkan konsisten. Berikut penerapan metode random forest menggunakan 500 tree.

```{r}
set.seed(777)
rf_origin_model <- randomForest(price_range ~ ., 
                                data = phone_train, 
                                importance=TRUE, 
                                ntree = 1000)
rf_origin_model

```

Informasi diatas merupakan informasi terkait model Random Forest yang dibuat. Model yang dibuat menggunakan 1000 tree dan jumlah variabel yang dicoba setiap percabangan ada 4 variabel. Lalu dari seluruh percobaan tersebut didapatkan nilai OOB (Out Of Box) dengan estimasi error rate pada data train sebesar **11.66%**. Perlu kita ketahui, semakin banyak jumlah tree pada model Random Forest maka akan semakin berat komputasi yang dilakukan, maka dari itu perlu kita lihat jumlah Tree yang optimal untuk diterapkan pada model.

```{r}
plot(rf_origin_model, main="Random Forest")
legend("topright", colnames(rf_origin_model$err.rate),col=1:6,cex=0.8,fill=1:6)
```

Grafik diatas menunjukan jumlah Tree dan Estimasi Error yang didapatkan. Dari 1000 tree yang dibuat, dapat dilihat nilai error menggunakan 370 sudah tergolong error minimum dari 1000 tree. Oleh karena itu, pada model random forest ini akan menggunakan 370 tree saja, sehingga beban komputasi berkurang.

```{r}
set.seed(777)
rf_origin_model <- randomForest(price_range ~ ., 
                                data = phone_train, 
                                importance=TRUE, 
                                ntree = 370)
rf_origin_model

```

Informasi diatas merupakan informasi terkait model Random Forest yang dibuat menggunakan 370 tree. Model dengan 370 tree menghasilkan nilai OOB (Out Of Box) dengan estimasi error rate sebesat 11.76%, yang dimana error ini relatif sama apabila menggunakan 1000 tree. Oleh karena, itu mari kita coba melakukan prediksi menggunakan model ini.


```{r}

# Predict to data Train
rf_origin_result_train <- cbind(phone_train, price_range_prediction=rf_origin_model$predicted,
                    round(rf_origin_model$votes,3))
# Data Predict
rf_origin_result_train <- rf_origin_result_train[,c(21,22,23,24,25,26)] %>% 
  setnames("price_range", "price_range_actual") %>%
  arrange(price_range_actual) %>% 
  mutate(
    no=seq(1:nrow(phone_train))
  ) %>% 
  select(7,1,2,3,4,5,6)




# Predict to Data Test
rf_prediction <- predict(rf_origin_model, phone_test)
rf_probability <- predict(rf_origin_model, phone_test, type="prob")

# Data Predict
rf_origin_result <- cbind(phone_test, price_range_prediction=rf_prediction,
                    round(rf_probability,3))

rf_origin_result <- rf_origin_result[,c(21,22,23,24,25,26)] %>% 
  setnames("price_range", "price_range_actual") %>%
  arrange(price_range_actual) %>% 
  mutate(
    no=seq(1:nrow(phone_test))
  ) %>% 
  select(7,1,2,3,4,5,6)

rf_origin_result
```

Data diatas merupakan hasil prediksi metode Random Forest menggunakan 170 tree terhadap data tes. **price_range_actual** merupakan data sebenarnya dan **price_range_prediction** merupakan data hasil prediksi, kemudian Data **low cost, medium cost, high cost dan very high cost** merupakan nilai probability terhadap setiap kelas dari target variabel. Sehingga, hasil prediksi pada **price_range_prediction** diambil berdasarkan nilai probability yang paling tinggi. Mari kita cek hasil evaluasinya menggunakan Confussion Matrix: 

```{r, fig.asp=0.5, fig.width = 12}
# Model Evaluation Random Forest with 370 tree
cfm_rf_origin_train <- confusionMatrix(
  data =rf_origin_result_train$price_range_prediction, 
  reference =rf_origin_result_train$price_range_actual
)

ggplotConfusionMatrix(my_title = "Random Forest: Model Evaluation on Data Train vs Data Test using Confussion Matrix",
                      dat_type="Train",
                      cfm=cfm_rf_origin_train,
                      low_color=mycolor_hex("smooth_blue"),
                      high_color =mycolor_hex("light_blue")) -> rf_p1


cfm_rf_origin <- confusionMatrix(
  data =rf_origin_result$price_range_prediction, 
  reference =rf_origin_result$price_range_actual
)


ggplotConfusionMatrix(my_title = "",
                      dat_type="Test",
                      cfm=cfm_rf_origin,
                      low_color=mycolor_hex("cream"),
                      high_color =mycolor_hex("dark_choc")) -> rf_p2

grid.arrange(rf_p1, rf_p2, ncol = 2)

```

```{r, echo=FALSE}

summaryMatrix(data_train=rf_origin_result_train,
              v_actual_train = rf_origin_result_train$price_range_actual,
              v_prediction_train = rf_origin_result_train$price_range_prediction,
              header_color_train = mycolor_hex("light_blue"),
              
              data_test=rf_origin_result,
              v_actual_test = rf_origin_result$price_range_actual,
              v_prediction_test = rf_origin_result$price_range_prediction,
              header_color_test = mycolor_hex("dark_choc")
              )

```


Hasil evaluasi model Random Forest menggunakan Confussion Matrix diatas menunjukan Tingkat akurasi hasil klasifikasi lumayan bagus, dimana tingkat akurasi pada data train sebesar **88.4%** dan tingkat akurasi pada data test sebesar **89.14%**. Dapat dilihat juga, hasil klasifikasi data test pada harga kelas Low Cost meleset sebanyak 8 ponsel, hasil prediksi harga kelas Medium Cost meleset sebanyak 9 ponsel, hasil prediksi harga kelas High Cost meleset 15 ponsel dan hasil prediksi Harga kelas Very Hight Cost meleset 11 ponsel. Namun, dapat kita simpulkan bahwa metode Random Forest ini lebih baik daripada metode Naive Bayes dan metode Decision Tree yang sudah dicoba sebelumnya. Selain itu model Random Forest ini dapat dikatakan Fit karena selisih akurasi klasifikasi pada data train dan data test cukup kecil yaitu **0.74%**. Mari kita coba Random Forest mengunakan K-Fold Cross Validation. 


***

<br>

### Random Forest with K-Fold Cross Validation

K-Fold Cross Validation adalah adalah salah satu metode Cross Validation yang membuat lipatan/partisi data sebanyak K dan mengulangi (meng-iterasi) experimennya sebanyak K juga. Pada pembagian train dan test sebelumnya, kita membagi data train sebanyak 1604 observasi. Misalkan kita menggunakan nilai K=10, berarti kita membagi 1604 data menjadi 10 partisi yang masing-masing memiliki 160 s.d. 161 data. Setelah melakukan 10 partisi, metode ini akan membagi 1 partisi sebagai data test dan 9 partisi lainnya menjadi data train untuk dilakukan iterasi sebanyak 10 kali. Dalam proses iterasi, setiap partisi akan mengalami proses sebagai data test dan data train sampai jumlah iterasi terpenuhi dengan syarat setiap iterasi menggunakan partisi data test dan partisi data train yang berbeda. Berikut ilustrasinya jika menggunakan K=5:

<center>
![](assets/kfolds.png){width=480px}
<br>sumber: http://ethen8181.github.io/machine-learning/model_selection/model_selection.html
</center>

<br>
<br>
**Beirkut pemodelan Random Forest dengan K-Fold Cross Validation menggunakan K=10**

```{r, eval=F, echo = TRUE}
# Random Forest method with K-Fold Cross Validation using K=10
set.seed(777)
kf_control <- trainControl(method = 'repeatedcv', number = 10, repeats = 10)
rf_model <- train(price_range ~.,
                  data = phone_train,
                  method = "rf",
                  trControl= kf_control)

wd <-  as.character(getwd())
saveRDS(object=rf_model, file=paste(paste(wd,"/model/",sep = ""),"phone_rf_kfold.rds",sep=""))
```

Chunk dari model diatas tidak dirunning karena memakan waktu yang cukup lama. Hasil model ini disimpan dalam RDS sehingga bisa langsung di load. berikut hasilnya:
```{r}
rf_kfold_model <- readRDS("model/phone_rf_kfold.rds")
#rf_model$finalModel[c("call", "confusion","oob.times")]
rf_kfold_model$finalModel

```

Data diatas merupakan informasi terkait model Random Forest dengan menerapkan K-Fold yang sudah dibuat. Model yang dibuat menggunakan 500 tree dan jumlah variabel yang dicoba setiap percabangan ada 11 variabel. Model ini mendapat nilai OOB (Out Of Box) dengan estimasi error rate pada data train sebesar **9.98%**, yang dimana nilai error lebih kecil daripada model Random Forest yang dibuat sebelumnya (poin 6.3.1). Jika dilihat, hal yang jelas berbeda dari model random forest sebelumnya yaitu jumlah variabel/prediktor yang digunakan. Pada model sebelumnya hanya menggunakan 4 variabel, dan pada model ini menggunakan 11 variabel pada pada setiap partisinya. Pertanyaannya mengapa?

```{r}
plot(rf_kfold_model, main="Selected Predictors vs Accuracy")
```


Kita tidak menentukan jumlah prediktor pada saat membuat model random forest ini, sehingga model akan memilih prediktor secara acak dan melakukan pembelajaran pada proses iterasi yang dilakukan, yang kemudian mencari akurasi optimum. Dapat dilihat pada plot diatas, akurasi optimum terletak ketika menggunakan 11 prediktor. Mari kita lihat, prediktor apa yang memiliki pengaruh besar pada model ini?

```{r}
varImp(rf_kfold_model)
```

Data diatas ditampilkan berurutan mulai dari variabel yang paling penting/berpengaruh dalam menentukan kelas harga. Dari 20 variabel prediktor yang kita punya, **ram** merupakan variabel yang paling penting dan **blue1** merupakan variabel yang paling tidak penting. Mari kita coba lihat hasil prediksi model ini terhadap data tes.

```{r}
# Predict to data Train
rf_kfold_prediction_train <- predict(rf_kfold_model, phone_train)
rf_kfold_probability_train <- predict(rf_kfold_model, phone_train, type = "prob")

rf_kfold_result_train <- cbind(phone_train, price_range_prediction=rf_kfold_prediction_train,
                    round(rf_kfold_probability_train,3))
                    
# Data Predict
rf_kfold_result_train <- rf_kfold_result_train[,c(21,22,23,24,25,26)] %>% 
  setnames("price_range", "price_range_actual") %>%
  arrange(price_range_actual) %>% 
  mutate(
    no=seq(1:nrow(phone_train))
  ) %>% 
  select(7,1,2,3,4,5,6)


# Predict to Data Test
rf_kfold_prediction <- predict(rf_kfold_model, phone_test)
rf_kfold_probability <- predict(rf_kfold_model, phone_test, type="prob")

# Data Predict
rf_kfold_result <- cbind(phone_test, price_range_prediction=rf_kfold_prediction,
                    round(rf_kfold_probability,3))

rf_kfold_result <- rf_kfold_result[,c(21,22,23,24,25,26)] %>% 
  setnames("price_range", "price_range_actual") %>%
  arrange(price_range_actual) %>% 
  mutate(
    no=seq(1:nrow(phone_test))
  ) %>% 
  select(7,1,2,3,4,5,6)

rf_kfold_result
```

Data diatas merupakan hasil prediksi metode Random Forest yang menerapkan K-Fold Cross Validation terhadap data tes. **price_range_actual** merupakan data sebenarnya dan **price_range_prediction** merupakan data hasil prediksi, kemudian Data **low cost, medium cost, high cost dan very high cost** merupakan nilai probability terhadap setiap kelas dari target variabel. Sehingga, hasil prediksi pada **price_range_prediction** diambil berdasarkan nilai probability yang paling tinggi. Mari kita cek hasil evaluasinya menggunakan Confussion Matrix: 


```{r, fig.asp=0.5, fig.width = 12}
# Model Evaluation Random Forest using K-Fold Cross Validation K=10
cfm_rf_kfold_train <- confusionMatrix(
  data =rf_kfold_result_train$price_range_prediction, 
  reference =rf_kfold_result_train$price_range_actual
)

ggplotConfusionMatrix(my_title = "Random Forest with K-Fold: Model Evaluation on Data Train vs Data Test using Confussion Matrix",
                      dat_type="Train",
                      cfm=cfm_rf_kfold_train,
                      low_color=mycolor_hex("smooth_blue"),
                      high_color =mycolor_hex("light_blue")) -> kfold_p1


cfm_rf_kfold <- confusionMatrix(
  data =rf_kfold_result$price_range_prediction, 
  reference =rf_kfold_result$price_range_actual
)


ggplotConfusionMatrix(my_title = "",
                      dat_type="Test",
                      cfm=cfm_rf_kfold,
                      low_color=mycolor_hex("cream"),
                      high_color =mycolor_hex("dark_choc")) -> kfold_p2

grid.arrange(kfold_p1, kfold_p2, ncol = 2)

```

```{r, echo=FALSE}
summaryMatrix(data_train=rf_kfold_result_train,
              v_actual_train = rf_kfold_result_train$price_range_actual,
              v_prediction_train = rf_kfold_result_train$price_range_prediction,
              header_color_train = mycolor_hex("light_blue"),
              
              data_test=rf_kfold_result,
              v_actual_test = rf_kfold_result$price_range_actual,
              v_prediction_test = rf_kfold_result$price_range_prediction,
              header_color_test = rf_kfold_result("dark_choc")
              )
```


Hasil evaluasi Confussion Matrix diatas menunjukan Tingkat akurasi hasil klasifikasi model ini **100%** apabila menggunakan data data train sedangkan tingkat akurasi pada data test sebesar **92.17%**. Dapat dilihat juga, hasil klasifikasi data test pada harga kelas Low Cost meleset sebanyak 6 ponsel, hasil prediksi harga kelas Medium Cost meleset sebanyak 10 ponsel, hasil prediksi harga kelas High Cost meleset 7 ponsel dan hasil prediksi Harga kelas Very Hight Cost meleset 8 ponsel. Jika hanya melihat tingkat akurasi saja, maka model ini merupakan model yang memiliki akurasi yang jauh lebih tinggi dari model Naive Bayes, Decision Tree dan Random Forest tanpa K-Fold, namun perlu dipertimbangkan dan butuh evaluasi lebih lanjut lagi karena model ini termasuk **Underfit model** dengan selisih yang cukup besar yaitu **7.83%**.

***

<br>



## Multinomial Regression
<p style="font-size:140%;"><b>Multinomial Logistic Regression (MLR)</b></p>
Multinomial Logistic Regression (MLR) merupakan regresi logistik yang digunakan saat variabel target bersifat multi-level atau lebih dari 2 kelas level. Sama seperti regresi linear dan regresi logistik, feature selection atau pemilihan variabel prediktor untuk pemodelan MLR bisa berdasarkan business wise atau dapat menggunakan pendekatan step-wise. Pada pemodelan ini, saya menggunakan model berdasarkan nilai AIC terkecil yang dihasilkan pendekatan step-wise. Berikut prosesnya:


```{r, eval=FALSE}
# Model Fitting
mlnom_all <- nnet::multinom(price_range~.,data=phone_train)

# Step wise
mlnom_step_model <- step(
  object = mlnom_all,
  direction = c("both", "backward", "forward"),
  trace = FALSE
)

wd <-  as.character(getwd())
saveRDS(object=mlnom_step_model, file=paste(paste(wd,"/model/",sep = ""),"mlnom_step_model.rds",sep=""))
```

Proses Step-wise diatas pada chunk diatas tidak saya jalankan karena hasilnya cukup panjang untuk ditampilkan. Namun berikut summary hasil pemodelannya:

```{r}
mlnom_step_model <- readRDS("model/mlnom_step_model.rds")
summary(mlnom_step_model)
```

Pada hasil summary model MLR diatas, nilai AIC terkecil dihasilkan yaitu 157.3763 dengan menggunakan 13 variabel.
Dari nilai koefisien ini bisa diketahui pengaruh dari variabel prediktor tersebut bersifat postif atau negatif terhadap masing-masing kelas harga. Mari kita coba lakukan prediksi.


```{r}
# Predict to data Train
mlnom_prediction_train <- predict(mlnom_step_model, phone_train)
mlnom_probability_train <- predict(mlnom_step_model, phone_train, type = "prob")

mlnom_result_train <- cbind(phone_train, price_range_prediction=mlnom_prediction_train,
                    round(mlnom_probability_train,3))
                    
# Data Predict
mlnom_result_train <- mlnom_result_train[,c(21,22,23,24,25,26)] %>% 
  setnames("price_range", "price_range_actual") %>%
  arrange(price_range_actual) %>% 
  mutate(
    no=seq(1:nrow(phone_train))
  ) %>% 
  select(7,1,2,3,4,5,6)


# Predict to Data Test
mlnom_prediction <- predict(mlnom_step_model, phone_test)
mlnom_probability <- predict(mlnom_step_model, phone_test, type="prob")

# Data Predict
mlnom_result <- cbind(phone_test, price_range_prediction=mlnom_prediction,
                    round(mlnom_probability,3))

mlnom_result <- mlnom_result[,c(21,22,23,24,25,26)] %>% 
  setnames("price_range", "price_range_actual") %>%
  arrange(price_range_actual) %>% 
  mutate(
    no=seq(1:nrow(phone_test))
  ) %>% 
  select(7,1,2,3,4,5,6)

mlnom_result

```

Data diatas merupakan hasil klasifikasi menggunakan metode Multinomial Logistic Regression terhadap data tes. **price_range_actual** merupakan data sebenarnya dan **price_range_prediction** merupakan data hasil prediksi, kemudian Data **low cost, medium cost, high cost dan very high cost** merupakan nilai probability terhadap setiap kelas dari target variabel. Sehingga, hasil prediksi pada **price_range_prediction** diambil berdasarkan nilai probability yang paling tinggi. Mari kita cek hasil evaluasinya menggunakan Confussion Matrix: 

```{r, fig.asp=0.5, fig.width=12}
# Model Evaluation MLR 
cfm_mlnom_train <- confusionMatrix(
  data = mlnom_result_train$price_range_prediction, 
  reference =mlnom_result_train$price_range_actual
)

ggplotConfusionMatrix(my_title = "Multinomial Regression: Model Evaluation on Data Train vs Data Test using Confussion Matrix",
                      dat_type="Train",
                      cfm=cfm_mlnom_train,
                      low_color=mycolor_hex("smooth_blue"),
                      high_color =mycolor_hex("light_blue")) -> mlnom_p1


cfm_mlnom <- confusionMatrix(
  data = mlnom_result$price_range_prediction, 
  reference = mlnom_result$price_range_actual
)


ggplotConfusionMatrix(my_title = "",
                      dat_type="Test",
                      cfm=cfm_mlnom,
                      low_color=mycolor_hex("cream"),
                      high_color =mycolor_hex("dark_choc")) -> mlnom_p2

grid.arrange(mlnom_p1, mlnom_p2, ncol = 2)
```

```{r, echo=FALSE}
summaryMatrix(data_train= mlnom_result_train,
              v_actual_train = mlnom_result_train$price_range_actual,
              v_prediction_train = mlnom_result_train$price_range_prediction,
              header_color_train = mycolor_hex("light_blue"),
              
              data_test=rf_kfold_result,
              v_actual_test = mlnom_result$price_range_actual,
              v_prediction_test = mlnom_result$price_range_prediction,
              header_color_test = mlnom_result("dark_choc")
              )
```

Hasil evaluasi menggunakan Confussion Matrix diatas menunjukan Tingkat akurasi hasil klasifikasi model ini 
**98.88%** apabila model ini diuji kembali terhadap data data train, sedangkan tingkat akurasi pada data test sebesar **97.73%**. Dapat dilihat juga, hasil klasifikasi data test pada harga kelas Low Cost meleset sebanyak 3 ponsel, hasil prediksi harga kelas Medium Cost meleset sebanyak 2 ponsel, hasil prediksi harga kelas High Cost meleset 2 ponsel dan hasil prediksi Harga kelas Very Hight Cost meleset 2 ponsel. Berdasar hasil tersebut, maka model ini dapat dikatakan Fit karena selisih akurasi klasifikasi pada data train dan data test cukup kecil yaitu **1.15%**. **Selain itu, dapat kita simpulkan bahwa metode Multinomial Logistic Regression ini lebih baik daripada metode Naive Bayes, Decision Tree dan Random Forest yang sudah dicoba sebelumnya khusus untuk case ini karena merupakan Fitted Model yang menghasilkan akurasi paling tinggi.**

***

<br>

# Model Implementation
Seperti yang dijelaskan sebelumnya, Bob ingin mengetahui klasifikasi harga dari setiap produk telepon seluler yang diproduksi oleh perusahaannya, sehinnga Bob memberikan 1000 data telepon seluler yang diproduksi oleh perusahaannya. Berikut data-datanya:
```{r}
phone_bob <- read.csv("data_input/phone_validation.csv")
data.frame("total.data" = dim(phone_bob)[1],
           "total.variabel" = dim(phone_bob)[2])

```

**Struktur Data**<br>
```{r}
glimpse(phone_bob)
```

<br>

Berdasarkan struktur data diatas, terdapat variabel-variabel yang tipe datanya perlu disesuaikan lagi berdasar sifat datanya sesuai dengan deskripsi variabel yang sudah dijelaskan pada poin 2.2. Adapun variabel yang perlu disesuaikan yaitu:
  1. *blue* :  di-konversi dari integer menjadi factor/kategorik <br>
  2. *dual_sim* : di-konversi dari integer menjadi factor/kategorik <br>
  3. *four_g* : di-konversi dari integer menjadi factor/kategorik <br>
  4. *three_g* : di-konversi dari integer menjadi factor/kategorik <br>
  5. *touch_screen* : di-konversi dari integer menjadi factor/kategorik <br>
  6. *wifi* : di-konversi dari integer menjadi factor/kategorik <br>
  

```{r}
id <- phone_bob$id
phone_bob <- phone_bob %>%
  mutate(
    blue = as.factor(blue),
    dual_sim  = as.factor(dual_sim),
    four_g = as.factor(four_g),
    three_g = as.factor(three_g),
    touch_screen = as.factor(touch_screen),
    wifi = as.factor(wifi)
  ) %>% 
  select(-id)

```
<br>

**Missing Value ?**<br>
Tidak terdapat missing value pada data ini, sehingga bisa kita lanjutkan ke tahap klasifikasi.
```{r}
colSums(is.na(phone_bob))
```

<br>

**Model Implementation**<br>
Berdasarkan hasil evaluasi model sebelumnya, model yang memiliki performa paling baik adalah model Multinomial Logistic Regression, sehinga kita akan menggunakan model tersebut untuk mengklasifikasikan telepon seluler miliki perusahaan Bob.

```{r}
# Predict to Data Test
mlnom_prediction_bob <- predict(mlnom_step_model, phone_bob)
mlnom_probability_bob <- predict(mlnom_step_model, phone_bob, type="prob")

# Data Predict
phone_classification <- cbind(id, price_range_prediction=mlnom_prediction_bob,
                    round(mlnom_probability_bob,3),phone_bob)

phone_classification %>% 
   arrange(id)
```

Data diatas merupakan hasil klasifikasi telepon seluler yang diproduksi oleh preusahaan Bob. **price_range_prediction** merupakan data hasil klasifikasi, kemudian Data **low cost, medium cost, high cost dan very high cost** merupakan nilai probability terhadap setiap kelas dari target variabel. Hasil prediksi pada **price_range_prediction** diambil berdasarkan nilai probability yang paling tinggi. Jika dilihat dari nilai probability yang dihasilkan, model ini sangat yakin dalam melakukan klasifikasi pada setiap datanya. Berikut proporsi hasil klasifikasinya:

```{r}
# Proportion of Result
phone_classification %>% group_by(price_range_prediction) %>% summarise(freq=n()) %>% 
ggplot( aes(x="", y=freq, fill=price_range_prediction)) + 
  geom_bar(stat="identity", width=1)+
  coord_polar("y", start=0) + 
  geom_text(aes(label = paste0(round((freq/sum(freq))*100), "%")),
            position = position_stack(vjust = 0.5),color="white")+
  scale_fill_manual(values=c(mycolor_hex("orange"),
                             mycolor_hex("semi_orange"),
                             mycolor_hex("light_orange"),
                             mycolor_hex("dark_orange"))) +
  labs(x = NULL, y = NULL, fill = "Price Range", title = "Proportion of Phone Price Classification Result on Bob's Company")+
  theme_classic() + 
  theme(axis.line = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        plot.title = element_text(hjust = 0.5),
        axis.title=element_text(size=9,face="bold"), 
        legend.position = "right"
        )

```

Pie chart diatas merupakan proporsi hasil klasifikasi harga telepon seluler yang diproduksi oleh perusahaan Bob. Proporsi paling tinggi yaitu telepon seluler kelas Very High Cost dan proporsi paling rendah adalah kelas Medium Cost. Namun secara keseluruhan proporsi ini cukup seimbang.


***

<br>

# Summary

Berdasarkan dataset dan pemodelan yang dilakukan, model **Multinomial Logistic Regression (MLR)** lebih baik daripada metode Naive Bayes, Decision Tree dan Random Forest khusus untuk case ini karena merupakan Fitted Model yang menghasilkan akurasi paling tinggi. Hasil evaluasi menggunakan Confussion Matrix pada model **MLR** menunjukan tingkat akurasi hasil klasifikasi model ini **98.88%** apabila model ini diuji kembali terhadap data data train, sedangkan tingkat akurasi pada data test sebesar **97.73%**. Sehinnga model ini yang paling layak diimplementasikan untuk masalah kalsifikasi harga telepon seluler di perusahaan Bob. Kemudian, berdasarkan proses implementasi model, diketahui telepon seluler kelas Very High Cost paling banyak diproduksi dan telepon seluler kelas Medium Cost paling sedikit diproduksi. Namun secara keseluruhan proporsi ini cukup seimbang, berikut detail jumlahnya:

```{r, echo=FALSE}
library(scales)
phone_classification %>% 
  group_by(price_range_prediction) %>% 
  summarise(freq=n()) %>% 
ggplot(aes(x=price_range_prediction, y=freq))+
geom_bar(aes(fill=freq), stat = "identity", position = "dodge",width = 0.9, show.legend = FALSE)+
geom_text(aes(label=freq, y=freq+10), vjust = -0.5, size=4) +
labs(
  title = "Summary of Mobile Price Classification on Bob's Company",
  x="Price Range",
  y="Total Phone"
)+
theme_minimal()+
 theme(
      axis.title=element_text(size=9, face="bold"),
      axis.text.x=element_text(size=9)
      ) +
scale_fill_gradient(low=mycolor_hex("cream"), high=mycolor_hex("light_orange"))
```



***

<br>

# Reference

1. [Wine Enthusiast II](https://rpubs.com/nabiilahardini/wine-ndf)
2. [Classification in Machine Learning 2](https://rpubs.com/knoxxturnal/Perbandingan_Analisis_Breast_Cancer_Dengan_Pendekatan_Metode_Naive_Bayes_Decision_Tree_dan_Random_Forest)
3. [How to use Multinomial and Ordinal Logistic Regression in R ?](https://www.analyticsvidhya.com/blog/2016/02/multinomial-ordinal-logistic-regression/)
4. [Mobile Price Classification](https://www.kaggle.com/iabhishekofficial/mobile-price-classification) 

